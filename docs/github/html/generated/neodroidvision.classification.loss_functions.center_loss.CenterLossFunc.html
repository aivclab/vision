<!DOCTYPE html>

<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
    <meta content="Docutils 0.17.1: http://docutils.sourceforge.net/" name="generator"/>

    <title>neodroidvision.classification.loss_functions.center_loss.CenterLossFunc &#8212; neodroidvision 0.2.9
        documentation</title>
    <link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
    <link href="../_static/alabaster.css" rel="stylesheet" type="text/css"/>
    <link href="../_static/graphviz.css" rel="stylesheet" type="text/css"/>
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link href="Neodroid.github.io/neodroidvision/generated/neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.html"
          rel="canonical"/>
    <link href="../genindex.html" rel="index" title="Index"/>
    <link href="../search.html" rel="search" title="Search"/>
    <link href="neodroidvision.classification.loss_functions.confidence_loss.html" rel="next"
          title="neodroidvision.classification.loss_functions.confidence_loss"/>
    <link href="neodroidvision.classification.loss_functions.center_loss.CenterLoss.html" rel="prev"
          title="neodroidvision.classification.loss_functions.center_loss.CenterLoss"/>

    <link href="../_static/custom.css" rel="stylesheet" type="text/css"/>


    <meta content="width=device-width, initial-scale=0.9, maximum-scale=0.9" name="viewport"/>

</head>
<body>


<div class="document">
    <div class="documentwrapper">
        <div class="bodywrapper">


            <div class="body" role="main">

                <section id="neodroidvision-classification-loss-functions-center-loss-centerlossfunc">
                    <h1>neodroidvision.classification.loss_functions.center_loss.CenterLossFunc<a class="headerlink"
                                                                                                  href="#neodroidvision-classification-loss-functions-center-loss-centerlossfunc"
                                                                                                  title="Permalink to this heading">¶</a>
                    </h1>
                    <dl class="py class">
                        <dt class="sig sig-object py"
                            id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc">
                            <em class="property"><span class="pre">class</span><span class="w"> </span></em><span
                                class="sig-prename descclassname"><span class="pre">neodroidvision.classification.loss_functions.center_loss.</span></span><span
                                class="sig-name descname"><span class="pre">CenterLossFunc</span></span><span
                                class="sig-paren">(</span><em class="sig-param"><span class="o"><span
                                class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>,
                            <em class="sig-param"><span class="o"><span class="pre">**</span></span><span
                                    class="n"><span class="pre">kwargs</span></span></em><span
                                class="sig-paren">)</span><a class="reference internal"
                                                             href="../_modules/neodroidvision/classification/loss_functions/center_loss.html#CenterLossFunc"><span
                                class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink"
                                                                                                     href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc"
                                                                                                     title="Permalink to this definition">¶</a>
                        </dt>
                        <dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Function</span></code>
                        </p>
                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.__init__">
                                    <span class="sig-name descname"><span class="pre">__init__</span></span><span
                                        class="sig-paren">(</span><em class="sig-param"><span class="o"><span
                                        class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>,
                                    <em class="sig-param"><span class="o"><span class="pre">**</span></span><span
                                            class="n"><span class="pre">kwargs</span></span></em><span
                                        class="sig-paren">)</span><a class="headerlink"
                                                                     href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.__init__"
                                                                     title="Permalink to this definition">¶</a></dt>
                                <dd></dd>
                            </dl>

                            <p class="rubric">Methods</p>
                            <table class="autosummary longtable docutils align-default">
                                <colgroup>
                                    <col style="width: 10%"/>
                                    <col style="width: 90%"/>
                                </colgroup>
                                <tbody>
                                <tr class="row-odd">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.__init__"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.__init__"><code
                                            class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a>(*args, **kwargs)
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward"><code
                                            class="xref py py-obj docutils literal notranslate"><span class="pre">backward</span></code></a>(ctx, grad_output)
                                    </p></td>
                                    <td><p>
                                        <dl class="field-list simple">
                                            <dt class="field-odd">param ctx</dt>
                                            <dd class="field-odd"><p></p></dd>
                                        </dl>
                                        </p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                            class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(ctx, feature, label, centers, batch_size)
                                    </p></td>
                                    <td><p>
                                        <dl class="field-list simple">
                                            <dt class="field-odd">param ctx</dt>
                                            <dd class="field-odd"><p></p></dd>
                                        </dl>
                                        </p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.jvp"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.jvp"><code
                                            class="xref py py-obj docutils literal notranslate"><span
                                            class="pre">jvp</span></code></a>(ctx, *grad_inputs)</p></td>
                                    <td><p>Defines a formula for differentiating the operation with forward mode
                                        automatic differentiation.</p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.mark_dirty"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.mark_dirty"><code
                                            class="xref py py-obj docutils literal notranslate"><span class="pre">mark_dirty</span></code></a>(*args)
                                    </p></td>
                                    <td><p>Marks given tensors as modified in an in-place operation.</p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.mark_non_differentiable"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.mark_non_differentiable"><code
                                            class="xref py py-obj docutils literal notranslate"><span class="pre">mark_non_differentiable</span></code></a>(*args)
                                    </p></td>
                                    <td><p>Marks outputs as non-differentiable.</p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">mark_shared_storage</span></code>(*pairs)
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_hook</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.save_for_backward"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.save_for_backward"><code
                                            class="xref py py-obj docutils literal notranslate"><span class="pre">save_for_backward</span></code></a>(*tensors)
                                    </p></td>
                                    <td><p>Saves given tensors for a future call to <code
                                            class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
                                    </p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.save_for_forward"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.save_for_forward"><code
                                            class="xref py py-obj docutils literal notranslate"><span class="pre">save_for_forward</span></code></a>(*tensors)
                                    </p></td>
                                    <td><p>Saves given tensors for a future call to <code
                                            class="xref py py-func docutils literal notranslate"><span
                                            class="pre">jvp()</span></code>.</p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.set_materialize_grads"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.set_materialize_grads"><code
                                            class="xref py py-obj docutils literal notranslate"><span class="pre">set_materialize_grads</span></code></a>(value)
                                    </p></td>
                                    <td><p>Sets whether to materialize output grad tensors.</p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><a class="reference internal"
                                              href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.vjp"
                                              title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.vjp"><code
                                            class="xref py py-obj docutils literal notranslate"><span
                                            class="pre">vjp</span></code></a>(ctx, *grad_outputs)</p></td>
                                    <td><p>Defines a formula for differentiating the operation with backward mode
                                        automatic differentiation (alias to the vjp function).</p></td>
                                </tr>
                                </tbody>
                            </table>
                            <p class="rubric">Attributes</p>
                            <table class="autosummary longtable docutils align-default">
                                <colgroup>
                                    <col style="width: 10%"/>
                                    <col style="width: 90%"/>
                                </colgroup>
                                <tbody>
                                <tr class="row-odd">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dirty_tensors</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_traceable</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">materialize_grads</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">metadata</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">needs_input_grad</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">next_functions</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">non_differentiable</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">saved_for_forward</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">saved_tensors</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-odd">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">saved_variables</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                <tr class="row-even">
                                    <td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_save</span></code>
                                    </p></td>
                                    <td><p></p></td>
                                </tr>
                                </tbody>
                            </table>
                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward">
                                    <em class="property"><span class="pre">static</span><span
                                            class="w"> </span></em><span class="sig-name descname"><span class="pre">backward</span></span><span
                                        class="sig-paren">(</span><em class="sig-param"><span class="n"><span
                                        class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span
                                        class="pre">grad_output</span></span></em><span class="sig-paren">)</span><a
                                        class="reference internal"
                                        href="../_modules/neodroidvision/classification/loss_functions/center_loss.html#CenterLossFunc.backward"><span
                                        class="viewcode-link"><span class="pre">[source]</span></span></a><a
                                        class="headerlink"
                                        href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward"
                                        title="Permalink to this definition">¶</a></dt>
                                <dd>
                                    <dl class="field-list simple">
                                        <dt class="field-odd">Parameters</dt>
                                        <dd class="field-odd">
                                            <ul class="simple">
                                                <li><p><strong>ctx</strong> – </p></li>
                                                <li><p><strong>grad_output</strong> – </p></li>
                                            </ul>
                                        </dd>
                                        <dt class="field-even">Returns</dt>
                                        <dd class="field-even"><p></p>
                                        </dd>
                                        <dt class="field-odd">Return type</dt>
                                        <dd class="field-odd"><p></p>
                                        </dd>
                                    </dl>
                                </dd>
                            </dl>

                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward">
                                    <em class="property"><span class="pre">static</span><span
                                            class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span
                                        class="sig-paren">(</span><em class="sig-param"><span class="n"><span
                                        class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span
                                        class="pre">feature</span></span></em>, <em class="sig-param"><span
                                        class="n"><span class="pre">label</span></span></em>, <em
                                        class="sig-param"><span class="n"><span class="pre">centers</span></span></em>,
                                    <em class="sig-param"><span class="n"><span
                                            class="pre">batch_size</span></span></em><span class="sig-paren">)</span>
                                    <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span
                                            class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a
                                        class="reference internal"
                                        href="../_modules/neodroidvision/classification/loss_functions/center_loss.html#CenterLossFunc.forward"><span
                                        class="viewcode-link"><span class="pre">[source]</span></span></a><a
                                        class="headerlink"
                                        href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                        title="Permalink to this definition">¶</a></dt>
                                <dd>
                                    <dl class="field-list simple">
                                        <dt class="field-odd">Parameters</dt>
                                        <dd class="field-odd">
                                            <ul class="simple">
                                                <li><p><strong>ctx</strong> – </p></li>
                                                <li><p><strong>feature</strong> – </p></li>
                                                <li><p><strong>label</strong> – </p></li>
                                                <li><p><strong>centers</strong> – </p></li>
                                                <li><p><strong>batch_size</strong> – </p></li>
                                            </ul>
                                        </dd>
                                        <dt class="field-even">Returns</dt>
                                        <dd class="field-even"><p></p>
                                        </dd>
                                        <dt class="field-odd">Return type</dt>
                                        <dd class="field-odd"><p></p>
                                        </dd>
                                    </dl>
                                </dd>
                            </dl>

                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.jvp">
                                    <em class="property"><span class="pre">static</span><span
                                            class="w"> </span></em><span class="sig-name descname"><span
                                        class="pre">jvp</span></span><span class="sig-paren">(</span><em
                                        class="sig-param"><span class="n"><span class="pre">ctx</span></span><span
                                        class="p"><span class="pre">:</span></span><span class="w"> </span><span
                                        class="n"><a class="reference external"
                                                     href="https://docs.python.org/3/library/typing.html#typing.Any"
                                                     title="(in Python v3.11)"><span
                                        class="pre">Any</span></a></span></em>, <em class="sig-param"><span
                                        class="o"><span class="pre">*</span></span><span class="n"><span class="pre">grad_inputs</span></span><span
                                        class="p"><span class="pre">:</span></span><span class="w"> </span><span
                                        class="n"><a class="reference external"
                                                     href="https://docs.python.org/3/library/typing.html#typing.Any"
                                                     title="(in Python v3.11)"><span
                                        class="pre">Any</span></a></span></em><span class="sig-paren">)</span> <span
                                        class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span
                                        class="sig-return-typehint"><a class="reference external"
                                                                       href="https://docs.python.org/3/library/typing.html#typing.Any"
                                                                       title="(in Python v3.11)"><span
                                        class="pre">Any</span></a></span></span><a class="headerlink"
                                                                                   href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.jvp"
                                                                                   title="Permalink to this definition">¶</a>
                                </dt>
                                <dd><p>Defines a formula for differentiating the operation with forward mode
                                    automatic differentiation.
                                    This function is to be overridden by all subclasses.
                                    It must accept a context <code class="xref py py-attr docutils literal notranslate"><span
                                            class="pre">ctx</span></code> as the first argument, followed by
                                    as many inputs as the <a class="reference internal"
                                                             href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                                             title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                            class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>
                                    got (None will be passed in
                                    for non tensor inputs of the forward function),
                                    and it should return as many tensors as there were outputs to
                                    <a class="reference internal"
                                       href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                       title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                            class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
                                    Each argument is the gradient w.r.t the given input,
                                    and each returned value should be the gradient w.r.t. the
                                    corresponding output. If an output is not a Tensor or the function is not
                                    differentiable with respect to that output, you can just pass None as a
                                    gradient for that input.</p>
                                    <p>You can use the <code class="xref py py-attr docutils literal notranslate"><span
                                            class="pre">ctx</span></code> object to pass any value from the forward to
                                        this
                                        functions.</p>
                                </dd>
                            </dl>

                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.mark_dirty">
                                    <span class="sig-name descname"><span class="pre">mark_dirty</span></span><span
                                        class="sig-paren">(</span><em class="sig-param"><span class="o"><span
                                        class="pre">*</span></span><span class="n"><span
                                        class="pre">args</span></span><span class="p"><span
                                        class="pre">:</span></span><span class="w"> </span><span class="n"><span
                                        class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a
                                        class="headerlink"
                                        href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.mark_dirty"
                                        title="Permalink to this definition">¶</a></dt>
                                <dd><p>Marks given tensors as modified in an in-place operation.</p>
                                    <p><strong>This should be called at most once, only from inside the</strong>
                                        <a class="reference internal"
                                           href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                           title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                                class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>
                                        <strong>method, and all arguments should be inputs.</strong></p>
                                    <p>Every tensor that’s been modified in-place in a call to <a
                                            class="reference internal"
                                            href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                            title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                            class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>
                                        should be given to this function, to ensure correctness of our checks.
                                        It doesn’t matter whether the function is called before or after
                                        modification.</p>
                                    <dl>
                                        <dt>Examples::</dt>
                                        <dd>
                                            <div class="doctest highlight-default notranslate">
                                                <div class="highlight"><pre><span></span><span
                                                        class="gp">&gt;&gt;&gt; </span><span
                                                        class="k">class</span> <span class="nc">Inplace</span><span
                                                        class="p">(</span><span class="n">Function</span><span
                                                        class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">forward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x_npy</span> <span class="o">=</span> <span
                                                            class="n">x</span><span class="o">.</span><span class="n">numpy</span><span
                                                            class="p">()</span> <span class="c1"># x_npy shares storage with x</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x_npy</span> <span class="o">+=</span> <span
                                                            class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">mark_dirty</span><span
                                                            class="p">(</span><span class="n">x</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@once_differentiable</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">backward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">grad_output</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">grad_output</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">tensor</span><span
                                                            class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span
                                                            class="n">requires_grad</span><span class="o">=</span><span
                                                            class="kc">True</span><span class="p">,</span> <span
                                                            class="n">dtype</span><span class="o">=</span><span
                                                            class="n">torch</span><span class="o">.</span><span
                                                            class="n">double</span><span class="p">)</span><span
                                                            class="o">.</span><span class="n">clone</span><span
                                                            class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span
                                                            class="o">*</span> <span class="n">a</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Inplace</span><span class="o">.</span><span
                                                            class="n">apply</span><span class="p">(</span><span
                                                            class="n">a</span><span class="p">)</span>  <span
                                                            class="c1"># This would lead to wrong gradients!</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="c1"># but the engine would not know unless we mark_dirty</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span
                                                            class="n">backward</span><span class="p">()</span> <span
                                                            class="c1"># RuntimeError: one of the variables needed for gradient</span>
<span class="gp">&gt;&gt;&gt; </span>             <span class="c1"># computation has been modified by an inplace operation</span>
</pre>
                                                </div>
                                            </div>
                                        </dd>
                                    </dl>
                                </dd>
                            </dl>

                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.mark_non_differentiable">
                                    <span class="sig-name descname"><span
                                            class="pre">mark_non_differentiable</span></span><span
                                        class="sig-paren">(</span><em class="sig-param"><span class="o"><span
                                        class="pre">*</span></span><span class="n"><span
                                        class="pre">args</span></span><span class="p"><span
                                        class="pre">:</span></span><span class="w"> </span><span class="n"><span
                                        class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a
                                        class="headerlink"
                                        href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.mark_non_differentiable"
                                        title="Permalink to this definition">¶</a></dt>
                                <dd><p>Marks outputs as non-differentiable.</p>
                                    <p><strong>This should be called at most once, only from inside the</strong>
                                        <a class="reference internal"
                                           href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                           title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                                class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>
                                        <strong>method, and all arguments should be tensor outputs.</strong></p>
                                    <p>This will mark outputs as not requiring gradients, increasing the
                                        efficiency of backward computation. You still need to accept a gradient
                                        for each output in <code
                                                class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code>,
                                        but it’s always going to
                                        be a zero tensor with the same shape as the shape of a corresponding
                                        output.</p>
                                    <dl>
                                        <dt>This is used e.g. for indices returned from a sort. See example::</dt>
                                        <dd>
                                            <div class="doctest highlight-default notranslate">
                                                <div class="highlight"><pre><span></span><span
                                                        class="gp">&gt;&gt;&gt; </span><span
                                                        class="k">class</span> <span class="nc">Func</span><span
                                                        class="p">(</span><span class="n">Function</span><span
                                                        class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">forward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">sorted</span><span class="p">,</span> <span
                                                            class="n">idx</span> <span class="o">=</span> <span
                                                            class="n">x</span><span class="o">.</span><span class="n">sort</span><span
                                                            class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">mark_non_differentiable</span><span
                                                            class="p">(</span><span class="n">idx</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span
                                                            class="p">(</span><span class="n">x</span><span
                                                            class="p">,</span> <span class="n">idx</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="nb">sorted</span><span
                                                            class="p">,</span> <span class="n">idx</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@once_differentiable</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">backward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span
                                                            class="p">):</span>  <span class="c1"># still need to accept g2</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span><span class="p">,</span> <span class="n">idx</span> <span
                                                            class="o">=</span> <span class="n">ctx</span><span
                                                            class="o">.</span><span class="n">saved_tensors</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">grad_input</span> <span class="o">=</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">zeros_like</span><span
                                                            class="p">(</span><span class="n">x</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">grad_input</span><span class="o">.</span><span class="n">index_add_</span><span
                                                            class="p">(</span><span class="mi">0</span><span
                                                            class="p">,</span> <span class="n">idx</span><span
                                                            class="p">,</span> <span class="n">g1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">grad_input</span>
</pre>
                                                </div>
                                            </div>
                                        </dd>
                                    </dl>
                                </dd>
                            </dl>

                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.save_for_backward">
                                    <span class="sig-name descname"><span
                                            class="pre">save_for_backward</span></span><span
                                        class="sig-paren">(</span><em class="sig-param"><span class="o"><span
                                        class="pre">*</span></span><span class="n"><span
                                        class="pre">tensors</span></span><span class="p"><span
                                        class="pre">:</span></span><span class="w"> </span><span class="n"><span
                                        class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a
                                        class="headerlink"
                                        href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.save_for_backward"
                                        title="Permalink to this definition">¶</a></dt>
                                <dd><p>Saves given tensors for a future call to <code
                                        class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.
                                </p>
                                    <p><code class="docutils literal notranslate"><span
                                            class="pre">save_for_backward</span></code> should be called at most once,
                                        only from inside the
                                        <a class="reference internal"
                                           href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                           title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                                class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>
                                        method, and only with tensors.</p>
                                    <p>All tensors intended to be used in the backward pass should be saved
                                        with <code class="docutils literal notranslate"><span class="pre">save_for_backward</span></code>
                                        (as opposed to directly on <code class="docutils literal notranslate"><span
                                                class="pre">ctx</span></code>) to prevent
                                        incorrect gradients and memory leaks, and enable the application of saved
                                        tensor hooks. See <code
                                                class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.graph.saved_tensors_hooks</span></code>.
                                    </p>
                                    <p>In <a class="reference internal"
                                             href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward"
                                             title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward"><code
                                            class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a>,
                                        saved tensors can be accessed through the <code
                                                class="xref py py-attr docutils literal notranslate"><span class="pre">saved_tensors</span></code>
                                        attribute. Before returning them to the user, a check is made to ensure
                                        they weren’t used in any in-place operation that modified their content.</p>
                                    <p>Arguments can also be <code class="docutils literal notranslate"><span
                                            class="pre">None</span></code>. This is a no-op.</p>
                                    <p>See <span class="xref std std-ref">extending-autograd</span> for more details on
                                        how to use this method.</p>
                                    <dl>
                                        <dt>Example::</dt>
                                        <dd>
                                            <div class="doctest highlight-default notranslate">
                                                <div class="highlight"><pre><span></span><span
                                                        class="gp">&gt;&gt;&gt; </span><span
                                                        class="k">class</span> <span class="nc">Func</span><span
                                                        class="p">(</span><span class="n">Function</span><span
                                                        class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">forward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">x</span><span class="p">:</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">Tensor</span><span
                                                            class="p">,</span> <span class="n">y</span><span
                                                            class="p">:</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">Tensor</span><span
                                                            class="p">,</span> <span class="n">z</span><span
                                                            class="p">:</span> <span class="nb">int</span><span
                                                            class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">w</span> <span class="o">=</span> <span class="n">x</span> <span
                                                            class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span
                                                            class="n">z</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">out</span> <span class="o">=</span> <span
                                                            class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span
                                                            class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span
                                                            class="n">z</span> <span class="o">+</span> <span class="n">w</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span
                                                            class="p">(</span><span class="n">x</span><span
                                                            class="p">,</span> <span class="n">y</span><span
                                                            class="p">,</span> <span class="n">w</span><span
                                                            class="p">,</span> <span class="n">out</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">z</span> <span
                                                            class="o">=</span> <span class="n">z</span>  <span
                                                            class="c1"># z is not a tensor</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">out</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">backward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">grad_out</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span><span class="p">,</span> <span
                                                            class="n">y</span><span class="p">,</span> <span
                                                            class="n">w</span><span class="p">,</span> <span class="n">out</span> <span
                                                            class="o">=</span> <span class="n">ctx</span><span
                                                            class="o">.</span><span class="n">saved_tensors</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">z</span> <span class="o">=</span> <span
                                                            class="n">ctx</span><span class="o">.</span><span class="n">z</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">gx</span> <span class="o">=</span> <span
                                                            class="n">grad_out</span> <span class="o">*</span> <span
                                                            class="p">(</span><span class="n">y</span> <span
                                                            class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span
                                                            class="n">z</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">gy</span> <span class="o">=</span> <span
                                                            class="n">grad_out</span> <span class="o">*</span> <span
                                                            class="p">(</span><span class="n">x</span> <span
                                                            class="o">+</span> <span class="n">z</span> <span class="o">+</span> <span
                                                            class="n">x</span> <span class="o">*</span> <span class="n">z</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">gz</span> <span class="o">=</span> <span
                                                            class="kc">None</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">gx</span><span
                                                            class="p">,</span> <span class="n">gy</span><span class="p">,</span> <span
                                                            class="n">gz</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">tensor</span><span
                                                            class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span
                                                            class="n">requires_grad</span><span class="o">=</span><span
                                                            class="kc">True</span><span class="p">,</span> <span
                                                            class="n">dtype</span><span class="o">=</span><span
                                                            class="n">torch</span><span class="o">.</span><span
                                                            class="n">double</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">tensor</span><span
                                                            class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span
                                                            class="n">requires_grad</span><span class="o">=</span><span
                                                            class="kc">True</span><span class="p">,</span> <span
                                                            class="n">dtype</span><span class="o">=</span><span
                                                            class="n">torch</span><span class="o">.</span><span
                                                            class="n">double</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">Func</span><span
                                                            class="o">.</span><span class="n">apply</span><span
                                                            class="p">(</span><span class="n">a</span><span
                                                            class="p">,</span> <span class="n">b</span><span
                                                            class="p">,</span> <span class="n">c</span><span
                                                            class="p">)</span>
</pre>
                                                </div>
                                            </div>
                                        </dd>
                                    </dl>
                                </dd>
                            </dl>

                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.save_for_forward">
                                    <span class="sig-name descname"><span
                                            class="pre">save_for_forward</span></span><span
                                        class="sig-paren">(</span><em class="sig-param"><span class="o"><span
                                        class="pre">*</span></span><span class="n"><span
                                        class="pre">tensors</span></span><span class="p"><span
                                        class="pre">:</span></span><span class="w"> </span><span class="n"><span
                                        class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a
                                        class="headerlink"
                                        href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.save_for_forward"
                                        title="Permalink to this definition">¶</a></dt>
                                <dd><p>Saves given tensors for a future call to <code
                                        class="xref py py-func docutils literal notranslate"><span
                                        class="pre">jvp()</span></code>.</p>
                                    <p><code class="docutils literal notranslate"><span
                                            class="pre">save_for_forward</span></code> should be only called once, from
                                        inside the <a class="reference internal"
                                                      href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                                      title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                                class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>
                                        method, and only be called with tensors.</p>
                                    <p>In <a class="reference internal"
                                             href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.jvp"
                                             title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.jvp"><code
                                            class="xref py py-func docutils literal notranslate"><span
                                            class="pre">jvp()</span></code></a>, saved objects can be accessed through
                                        the <code class="xref py py-attr docutils literal notranslate"><span
                                                class="pre">saved_tensors</span></code>
                                        attribute.</p>
                                    <p>Arguments can also be <code class="docutils literal notranslate"><span
                                            class="pre">None</span></code>. This is a no-op.</p>
                                    <p>See <span class="xref std std-ref">extending-autograd</span> for more details on
                                        how to use this method.</p>
                                    <dl>
                                        <dt>Example::</dt>
                                        <dd>
                                            <div class="doctest highlight-default notranslate">
                                                <div class="highlight"><pre><span></span><span
                                                        class="gp">&gt;&gt;&gt; </span><span
                                                        class="k">class</span> <span class="nc">Func</span><span
                                                        class="p">(</span><span class="n">torch</span><span
                                                        class="o">.</span><span class="n">autograd</span><span
                                                        class="o">.</span><span class="n">Function</span><span
                                                        class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">forward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">x</span><span class="p">:</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">Tensor</span><span
                                                            class="p">,</span> <span class="n">y</span><span
                                                            class="p">:</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">Tensor</span><span
                                                            class="p">,</span> <span class="n">z</span><span
                                                            class="p">:</span> <span class="nb">int</span><span
                                                            class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span
                                                            class="p">(</span><span class="n">x</span><span
                                                            class="p">,</span> <span class="n">y</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_forward</span><span
                                                            class="p">(</span><span class="n">x</span><span
                                                            class="p">,</span> <span class="n">y</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">z</span> <span
                                                            class="o">=</span> <span class="n">z</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span> <span
                                                            class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span
                                                            class="n">z</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">jvp</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">x_t</span><span class="p">,</span> <span
                                                            class="n">y_t</span><span class="p">,</span> <span
                                                            class="n">_</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span><span class="p">,</span> <span
                                                            class="n">y</span> <span class="o">=</span> <span class="n">ctx</span><span
                                                            class="o">.</span><span class="n">saved_tensors</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">z</span> <span class="o">=</span> <span
                                                            class="n">ctx</span><span class="o">.</span><span class="n">z</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">z</span> <span
                                                            class="o">*</span> <span class="p">(</span><span
                                                            class="n">y</span> <span class="o">*</span> <span class="n">x_t</span> <span
                                                            class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span
                                                            class="n">y_t</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">vjp</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">grad_out</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span><span class="p">,</span> <span
                                                            class="n">y</span> <span class="o">=</span> <span class="n">ctx</span><span
                                                            class="o">.</span><span class="n">saved_tensors</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">z</span> <span class="o">=</span> <span
                                                            class="n">ctx</span><span class="o">.</span><span class="n">z</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">z</span> <span
                                                            class="o">*</span> <span class="n">grad_out</span> <span
                                                            class="o">*</span> <span class="n">y</span><span
                                                            class="p">,</span> <span class="n">z</span> <span class="o">*</span> <span
                                                            class="n">grad_out</span> <span class="o">*</span> <span
                                                            class="n">x</span><span class="p">,</span> <span class="kc">None</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">a</span> <span class="o">=</span> <span
                                                            class="n">torch</span><span class="o">.</span><span
                                                            class="n">tensor</span><span class="p">(</span><span
                                                            class="mf">1.</span><span class="p">,</span> <span
                                                            class="n">requires_grad</span><span class="o">=</span><span
                                                            class="kc">True</span><span class="p">,</span> <span
                                                            class="n">dtype</span><span class="o">=</span><span
                                                            class="n">torch</span><span class="o">.</span><span
                                                            class="n">double</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">t</span> <span class="o">=</span> <span
                                                            class="n">torch</span><span class="o">.</span><span
                                                            class="n">tensor</span><span class="p">(</span><span
                                                            class="mf">1.</span><span class="p">,</span> <span
                                                            class="n">dtype</span><span class="o">=</span><span
                                                            class="n">torch</span><span class="o">.</span><span
                                                            class="n">double</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">b</span> <span class="o">=</span> <span
                                                            class="n">torch</span><span class="o">.</span><span
                                                            class="n">tensor</span><span class="p">(</span><span
                                                            class="mf">2.</span><span class="p">,</span> <span
                                                            class="n">requires_grad</span><span class="o">=</span><span
                                                            class="kc">True</span><span class="p">,</span> <span
                                                            class="n">dtype</span><span class="o">=</span><span
                                                            class="n">torch</span><span class="o">.</span><span
                                                            class="n">double</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">c</span> <span class="o">=</span> <span class="mi">4</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">with</span> <span class="n">fwAD</span><span class="o">.</span><span
                                                            class="n">dual_level</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">a_dual</span> <span class="o">=</span> <span
                                                            class="n">fwAD</span><span class="o">.</span><span
                                                            class="n">make_dual</span><span class="p">(</span><span
                                                            class="n">a</span><span class="p">,</span> <span
                                                            class="n">t</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">d</span> <span class="o">=</span> <span
                                                            class="n">Func</span><span class="o">.</span><span
                                                            class="n">apply</span><span class="p">(</span><span
                                                            class="n">a_dual</span><span class="p">,</span> <span
                                                            class="n">b</span><span class="p">,</span> <span
                                                            class="n">c</span><span class="p">)</span>
</pre>
                                                </div>
                                            </div>
                                        </dd>
                                    </dl>
                                </dd>
                            </dl>

                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.set_materialize_grads">
                                    <span class="sig-name descname"><span
                                            class="pre">set_materialize_grads</span></span><span
                                        class="sig-paren">(</span><em class="sig-param"><span class="n"><span
                                        class="pre">value</span></span><span class="p"><span class="pre">:</span></span><span
                                        class="w"> </span><span class="n"><a class="reference external"
                                                                             href="https://docs.python.org/3/library/functions.html#bool"
                                                                             title="(in Python v3.11)"><span
                                        class="pre">bool</span></a></span></em><span class="sig-paren">)</span><a
                                        class="headerlink"
                                        href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.set_materialize_grads"
                                        title="Permalink to this definition">¶</a></dt>
                                <dd><p>Sets whether to materialize output grad tensors. Default is <code
                                        class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
                                    <p><strong>This should be called only from inside the</strong> <a
                                            class="reference internal"
                                            href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                            title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                            class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>
                                        <strong>method</strong></p>
                                    <p>If <code class="docutils literal notranslate"><span
                                            class="pre">True</span></code>, undefined output grad tensors will be
                                        expanded to tensors full
                                        of zeros prior to calling the <a class="reference internal"
                                                                         href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward"
                                                                         title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward"><code
                                                class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a>
                                        method.</p>
                                    <dl>
                                        <dt>Example::</dt>
                                        <dd>
                                            <div class="doctest highlight-default notranslate">
                                                <div class="highlight"><pre><span></span><span
                                                        class="gp">&gt;&gt;&gt; </span><span
                                                        class="k">class</span> <span class="nc">SimpleFunc</span><span
                                                        class="p">(</span><span class="n">Function</span><span
                                                        class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">forward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span><span
                                                            class="o">.</span><span class="n">clone</span><span
                                                            class="p">(),</span> <span class="n">x</span><span
                                                            class="o">.</span><span class="n">clone</span><span
                                                            class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@once_differentiable</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">backward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span
                                                            class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">g1</span> <span
                                                            class="o">+</span> <span class="n">g2</span>  <span
                                                            class="c1"># No check for None necessary</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># We modify SimpleFunc to handle non-materialized grad outputs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Func</span><span
                                                            class="p">(</span><span class="n">Function</span><span
                                                            class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">forward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">x</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">set_materialize_grads</span><span
                                                            class="p">(</span><span class="kc">False</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span
                                                            class="p">(</span><span class="n">x</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">x</span><span
                                                            class="o">.</span><span class="n">clone</span><span
                                                            class="p">(),</span> <span class="n">x</span><span
                                                            class="o">.</span><span class="n">clone</span><span
                                                            class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@staticmethod</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nd">@once_differentiable</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">def</span> <span class="nf">backward</span><span
                                                            class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span
                                                            class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span
                                                            class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span><span class="p">,</span> <span
                                                            class="o">=</span> <span class="n">ctx</span><span
                                                            class="o">.</span><span class="n">saved_tensors</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">grad_input</span> <span class="o">=</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">zeros_like</span><span
                                                            class="p">(</span><span class="n">x</span><span
                                                            class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">if</span> <span class="n">g1</span> <span
                                                            class="ow">is</span> <span class="ow">not</span> <span
                                                            class="kc">None</span><span class="p">:</span>  <span
                                                            class="c1"># We must check for None now</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="n">grad_input</span> <span class="o">+=</span> <span
                                                            class="n">g1</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">if</span> <span class="n">g2</span> <span
                                                            class="ow">is</span> <span class="ow">not</span> <span
                                                            class="kc">None</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="n">grad_input</span> <span class="o">+=</span> <span
                                                            class="n">g2</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">return</span> <span class="n">grad_input</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span
                                                            class="o">.</span><span class="n">tensor</span><span
                                                            class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span
                                                            class="n">requires_grad</span><span class="o">=</span><span
                                                            class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="p">,</span> <span class="n">_</span> <span
                                                            class="o">=</span> <span class="n">Func</span><span
                                                            class="o">.</span><span class="n">apply</span><span
                                                            class="p">(</span><span class="n">a</span><span
                                                            class="p">)</span>  <span class="c1"># induces g2 to be undefined</span>
</pre>
                                                </div>
                                            </div>
                                        </dd>
                                    </dl>
                                </dd>
                            </dl>

                            <dl class="py method">
                                <dt class="sig sig-object py"
                                    id="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.vjp">
                                    <em class="property"><span class="pre">static</span><span
                                            class="w"> </span></em><span class="sig-name descname"><span
                                        class="pre">vjp</span></span><span class="sig-paren">(</span><em
                                        class="sig-param"><span class="n"><span class="pre">ctx</span></span><span
                                        class="p"><span class="pre">:</span></span><span class="w"> </span><span
                                        class="n"><a class="reference external"
                                                     href="https://docs.python.org/3/library/typing.html#typing.Any"
                                                     title="(in Python v3.11)"><span
                                        class="pre">Any</span></a></span></em>, <em class="sig-param"><span
                                        class="o"><span class="pre">*</span></span><span class="n"><span class="pre">grad_outputs</span></span><span
                                        class="p"><span class="pre">:</span></span><span class="w"> </span><span
                                        class="n"><a class="reference external"
                                                     href="https://docs.python.org/3/library/typing.html#typing.Any"
                                                     title="(in Python v3.11)"><span
                                        class="pre">Any</span></a></span></em><span class="sig-paren">)</span> <span
                                        class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span
                                        class="sig-return-typehint"><a class="reference external"
                                                                       href="https://docs.python.org/3/library/typing.html#typing.Any"
                                                                       title="(in Python v3.11)"><span
                                        class="pre">Any</span></a></span></span><a class="headerlink"
                                                                                   href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.vjp"
                                                                                   title="Permalink to this definition">¶</a>
                                </dt>
                                <dd><p>Defines a formula for differentiating the operation with backward mode
                                    automatic differentiation (alias to the vjp function).</p>
                                    <p>This function is to be overridden by all subclasses.</p>
                                    <p>It must accept a context <code
                                            class="xref py py-attr docutils literal notranslate"><span
                                            class="pre">ctx</span></code> as the first argument, followed by
                                        as many outputs as the <a class="reference internal"
                                                                  href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                                                  title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                                class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>
                                        returned (None will be passed in
                                        for non tensor outputs of the forward function),
                                        and it should return as many tensors, as there were inputs to
                                        <a class="reference internal"
                                           href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                           title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                                class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
                                        Each argument is the gradient w.r.t the given output,
                                        and each returned value should be the gradient w.r.t. the
                                        corresponding input. If an input is not a Tensor or is a Tensor not
                                        requiring grads, you can just pass None as a gradient for that input.</p>
                                    <p>The context can be used to retrieve tensors saved during the forward
                                        pass. It also has an attribute <code
                                                class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code>
                                        as a tuple
                                        of booleans representing whether each input needs gradient. E.g.,
                                        <a class="reference internal"
                                           href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward"
                                           title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.backward"><code
                                                class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a>
                                        will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span>
                                            <span class="pre">=</span> <span class="pre">True</span></code> if the
                                        first input to <a class="reference internal"
                                                          href="#neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"
                                                          title="neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.forward"><code
                                                class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>
                                        needs gradient computated w.r.t. the
                                        output.</p>
                                </dd>
                            </dl>

                        </dd>
                    </dl>

                </section>


            </div>

        </div>
    </div>
    <div aria-label="main navigation" class="sphinxsidebar" role="navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
                <img alt="Logo" class="logo" src="../_static/header.png"/>
            </a></p>
            <h1 class="logo"><a href="../index.html">neodroidvision</a></h1>


            <h3>Navigation</h3>
            <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal"
                                                  href="neodroidvision.html">neodroidvision</a>
                    <ul class="current">
                        <li class="toctree-l2"><a class="reference internal"
                                                  href="neodroidvision.dist_is_editable.html">neodroidvision.dist_is_editable</a>
                        </li>
                        <li class="toctree-l2"><a class="reference internal" href="neodroidvision.get_version.html">neodroidvision.get_version</a>
                        </li>
                        <li class="toctree-l2 current"><a class="reference internal"
                                                          href="neodroidvision.classification.html">neodroidvision.classification</a>
                            <ul class="current">
                                <li class="toctree-l3"><a class="reference internal"
                                                          href="neodroidvision.classification.architectures.html">neodroidvision.classification.architectures</a>
                                </li>
                                <li class="toctree-l3 current"><a class="reference internal"
                                                                  href="neodroidvision.classification.loss_functions.html">neodroidvision.classification.loss_functions</a>
                                    <ul class="current">
                                        <li class="toctree-l4 current"><a class="reference internal"
                                                                          href="neodroidvision.classification.loss_functions.center_loss.html">neodroidvision.classification.loss_functions.center_loss</a>
                                            <ul class="current">
                                                <li class="toctree-l5"><a class="reference internal"
                                                                          href="neodroidvision.classification.loss_functions.center_loss.CenterLoss.html">neodroidvision.classification.loss_functions.center_loss.CenterLoss</a>
                                                </li>
                                                <li class="toctree-l5 current"><a class="current reference internal"
                                                                                  href="#">neodroidvision.classification.loss_functions.center_loss.CenterLossFunc</a>
                                                </li>
                                            </ul>
                                        </li>
                                        <li class="toctree-l4"><a class="reference internal"
                                                                  href="neodroidvision.classification.loss_functions.confidence_loss.html">neodroidvision.classification.loss_functions.confidence_loss</a>
                                        </li>
                                        <li class="toctree-l4"><a class="reference internal"
                                                                  href="neodroidvision.classification.loss_functions.ranking.html">neodroidvision.classification.loss_functions.ranking</a>
                                        </li>
                                    </ul>
                                </li>
                                <li class="toctree-l3"><a class="reference internal"
                                                          href="neodroidvision.classification.mechanims.html">neodroidvision.classification.mechanims</a>
                                </li>
                                <li class="toctree-l3"><a class="reference internal"
                                                          href="neodroidvision.classification.procedures.html">neodroidvision.classification.procedures</a>
                                </li>
                            </ul>
                        </li>
                        <li class="toctree-l2"><a class="reference internal" href="neodroidvision.data.html">neodroidvision.data</a>
                        </li>
                        <li class="toctree-l2"><a class="reference internal" href="neodroidvision.detection.html">neodroidvision.detection</a>
                        </li>
                        <li class="toctree-l2"><a class="reference internal" href="neodroidvision.entry_points.html">neodroidvision.entry_points</a>
                        </li>
                        <li class="toctree-l2"><a class="reference internal" href="neodroidvision.mixed.html">neodroidvision.mixed</a>
                        </li>
                        <li class="toctree-l2"><a class="reference internal" href="neodroidvision.multitask.html">neodroidvision.multitask</a>
                        </li>
                        <li class="toctree-l2"><a class="reference internal" href="neodroidvision.regression.html">neodroidvision.regression</a>
                        </li>
                        <li class="toctree-l2"><a class="reference internal" href="neodroidvision.segmentation.html">neodroidvision.segmentation</a>
                        </li>
                        <li class="toctree-l2"><a class="reference internal" href="neodroidvision.utilities.html">neodroidvision.utilities</a>
                        </li>
                    </ul>
                </li>
            </ul>
            <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
            <ul>
                <li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a>
                </li>
            </ul>

            <div class="relations">
                <h3>Related Topics</h3>
                <ul>
                    <li><a href="../index.html">Documentation overview</a>
                        <ul>
                            <li><a href="neodroidvision.html">neodroidvision</a>
                                <ul>
                                    <li><a href="neodroidvision.classification.html">neodroidvision.classification</a>
                                        <ul>
                                            <li><a href="neodroidvision.classification.loss_functions.html">neodroidvision.classification.loss_functions</a>
                                                <ul>
                                                    <li>
                                                        <a href="neodroidvision.classification.loss_functions.center_loss.html">neodroidvision.classification.loss_functions.center_loss</a>
                                                        <ul>
                                                            <li>Previous: <a
                                                                    href="neodroidvision.classification.loss_functions.center_loss.CenterLoss.html"
                                                                    title="previous chapter">neodroidvision.classification.loss_functions.center_loss.CenterLoss</a>
                                                            </li>
                                                            <li>Next: <a
                                                                    href="neodroidvision.classification.loss_functions.confidence_loss.html"
                                                                    title="next chapter">neodroidvision.classification.loss_functions.confidence_loss</a>
                                                            </li>
                                                        </ul>
                                                    </li>
                                                </ul>
                                            </li>
                                        </ul>
                                    </li>
                                </ul>
                            </li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div id="searchbox" role="search" style="display: none">
                <h3 id="searchlabel">Quick search</h3>
                <div class="searchformwrapper">
                    <form action="../search.html" class="search" method="get">
                        <input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q"
                               spellcheck="false" type="text"/>
                        <input type="submit" value="Go"/>
                    </form>
                </div>
            </div>
            <script>document.getElementById('searchbox').style.display = "block"</script>


        </div>
    </div>
    <div class="clearer"></div>
</div>
<div class="footer">
    &copy;.

    |
    Powered by <a href="http://sphinx-doc.org/">Sphinx 5.0.2</a>
    &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>

    |
    <a href="../_sources/generated/neodroidvision.classification.loss_functions.center_loss.CenterLossFunc.rst.txt"
       rel="nofollow">Page source</a>
</div>


</body>
</html>